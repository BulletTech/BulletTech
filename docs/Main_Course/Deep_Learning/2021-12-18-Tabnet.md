---
template: overrides/blogs.html
---

# TabNet小介

!!! info
    作者：谁是Void，发布于2021-12-18，阅读时间：约6分钟，微信公众号文章链接：[:fontawesome-solid-link:](https://mp.weixin.qq.com/s?__biz=MzI4Mjk3NzgxOQ==&mid=2247484578&idx=1&sn=54593557289d011ac6aff472597a731b&chksm=eb90f7d6dce77ec0d896ff1149f89f4c6d9bab7753be123ef269aa781a3ae88012bfa90ce2e0&token=221998215&lang=zh_CN#rd)

## 1 前言

对于表格型数据，树模型(LightGBM，XGBoost)往往能有不错的表现。可能的原因有:

- 容易构造或已经有丰富的特征库。
- 树模型的决策流形(decision manifolds)是超平面边界的(可以理解为一刀一刀切出来的)，对此类问题表现较好。

由于NN模型(Neural Network Model)的表现只能算差强人意，而我们又需要有NN模型参与最后的模型ensemble，机智的研究者们为此设计出了类似树模型的NN模型。本文将介绍的就是此类模型：TabNet。

## 2 用NN构造决策树

决策树我们可能已经比较熟悉了，它的决策边界可见如下简单示例：

<figure>
  <img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-6-14/1623639526512-1080P%20(Full%20HD)%20-%20Tail%20Pic.png" width="500" />
</figure>

两个特征x1，x2分别以阈值a，b进行划分，将数据集划分成4块。那么NN如何能模拟这一过程呢？

<figure>
  <img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-6-14/1623639526512-1080P%20(Full%20HD)%20-%20Tail%20Pic.png" width="500" />
</figure>

模型的输入同样是x1，x2两个特征，首先通过Mask层将它们分别筛选出来，因为树模型在构造的过程中，也是独立的在每一步选择分裂增益最大的那`一个特征`。  
接着，两个特征分别接了一个设计好权重和bias的全连接层，并通过RELU激活函数输出。  
由于RELU(x)在x>0时，即为x，小于0时，为0。那么对于x1来说，当x1>a时，最终输出为[c1*x1-c1*a,0,0,0]，若x1<a，输出为[0,-c1*x1+c1*a,0,0]。可以看到这里相当于以a为阈值，进行划分。这里的两个-1维度其实是用来对齐填充维度的。  

最终，我们把不同特征的输出加起来，并作用softmax，得到输出向量，如[0.1,0.5,0.3,0.3]。其中，每一维代表某个条件成立时，对最终决策的影响权重。如0.1代表x1>a对最终决策的影响权重只有10%。

## 3 总结

本文总结了若干常用的tf.keras.callbacks，实际工作中，请按需使用，并且查看tf.keras.callbacks的官方文档确认参数取值。

希望这次的分享对你有帮助，欢迎在评论区留言讨论！

<figure>
  <img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-6-14/1623639526512-1080P%20(Full%20HD)%20-%20Tail%20Pic.png" width="500" />
</figure>

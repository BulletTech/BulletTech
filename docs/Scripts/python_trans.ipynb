{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate docs into other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''\n",
    "\n",
    "\n",
    "def send_message(prompt, message):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt + message,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are you doing\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "translated = translator.translate('Mitä sinä teet')\n",
    "print(translated.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "### Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder_list = ['../en/Dessert','../en/Main_Course']\n",
    "\n",
    "Post_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../en/Dessert/Hardware/2021-06-03-Mac-mini.md'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for folder in Folder_list:\n",
    "    for root, directories, files in os.walk(folder, topdown=False):\n",
    "        for name in files:\n",
    "            if '.md' in name:\n",
    "                Post_list.append(os.path.join(root, name))\n",
    "Post_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vincent_docs = []\n",
    "for path_ in Post_list:\n",
    "    with open(path_, 'r') as f:\n",
    "        if 'Vincent' in ''.join(f.readlines()):\n",
    "            vincent_docs.append(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vincent_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the docs to an new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_ in vincent_docs:\n",
    "    !cp $file_ /Users/vincent.yuan/Downloads/vincent_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google translation processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_post(text_lines, translator, lang):\n",
    "    split_point_ = 0\n",
    "    # Find the position that starts the body, the headers and body should be processed separately\n",
    "    for no_, block_ in enumerate(text_lines):\n",
    "        if '##' in block_:\n",
    "            split_point_ = no_\n",
    "            print(f'Header ends at no.{split_point_} block...')\n",
    "            break\n",
    "    \n",
    "    \n",
    "    headers_ = text_lines[:split_point_]\n",
    "    body_ = text_lines[split_point_:]\n",
    "    \n",
    "    def translate_header_(_headers_, lang):\n",
    "        if lang == 'en':\n",
    "            en_headers_ = _headers_.replace('作者', 'Author:')\\\n",
    "                                    .replace('发布于', 'Posted on ')\\\n",
    "                                    .replace('阅读时间：约','Reading time: ')\\\n",
    "                                    .replace('分钟', ' mins')\\\n",
    "                                    .replace('微信公众号文章链接','WeChat Post Link:')\n",
    "            return en_headers_\n",
    "        else:\n",
    "            print(f'{lang} cannot be well verified, so the original headers are returned.')\n",
    "            return _headers_\n",
    "    \n",
    "    def translate_body_(body_: list, lang: str):\n",
    "        import time\n",
    "        import re\n",
    "        en_body_ = []\n",
    "        if lang == 'en':\n",
    "            for text_ in body_:\n",
    "                # exclusion of special chars\n",
    "                if 'img' in text_ or text_ == '\\n':\n",
    "                    en_body_.append(text_)\n",
    "                \n",
    "                # Skip hyper links\n",
    "                elif re.findall(r'(\\[.+\\]\\(.+\\))', text_):\n",
    "                    \n",
    "                    hyper_link_ = re.findall(r'(\\[.+\\]\\(.+\\))', text_)\n",
    "\n",
    "                    if hyper_link_:\n",
    "\n",
    "                        split_text = re.split(r'(\\[.+\\]\\(.+\\))', text_, maxsplit=0)\n",
    "                        for txt_ in split_text:\n",
    "                            \n",
    "                            if txt_ != hyper_link_ and txt_ != '' and  txt_ != '\\n':\n",
    "                                try:\n",
    "                                    en_body_.append(translator.translate(str(txt_)).text)\n",
    "                                except:\n",
    "                                    print(txt_)\n",
    "                                    pass\n",
    "                            \n",
    "                            elif  txt_ != '' and  txt_ != '\\n':\n",
    "                                en_body_.append(txt_)\n",
    "                            else:\n",
    "                                pass\n",
    "                else:\n",
    "                    # Sleep 300 milliseconds\n",
    "                    time.sleep(300/1000)\n",
    "                    en_body_.append(translator.translate(str(text_)).text)\n",
    "            return en_body_\n",
    "        else:\n",
    "            print(f'{lang} cannot be well verified, so the original body are returned.')\n",
    "            return body_\n",
    "    \n",
    "    translated_headers = translate_header_(''.join(headers_), lang)\n",
    "    translated_body = translate_body_(body_, lang)\n",
    "    \n",
    "    return translated_headers + '\\n'.join(translated_body)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"translate below text into English: \"\n",
    "\n",
    "\n",
    "undone_post_key = []\n",
    "chn_posts = {}\n",
    "en_posts = {}\n",
    "for post_path in Post_list:\n",
    "    print(f'Processing {post_path}...')\n",
    "    with open(post_path, 'r') as f:\n",
    "        post_text_ = f.readlines()\n",
    "        # if 'Vincent' in ''.join(post_text_):\n",
    "        chn_posts[post_path] = post_text_\n",
    "        # split the text if the number of tokens are greater than 4097\n",
    "        # try:\n",
    "        #     en_posts[post_path] = send_message(prompt=prompt,\n",
    "        #                                         message=''.join(post_text_)\n",
    "        #                                         )\n",
    "        # except:\n",
    "        #     undone_post_key.append(post_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append post headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "\n",
    "---\n",
    "template: overrides/blogs.html\n",
    "tags:\n",
    "  - python\n",
    "---\n",
    "\n",
    "\n",
    "# test\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_copy = test_text.lstrip('\\n').split('---')\n",
    "test_text_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_post_headers(post_text):\n",
    "    header = post_text.lstrip('\\n').split('---')[1]\n",
    "    header = \"---\" + header + '---\\n\\n'\n",
    "    return header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_, text_ in chn_posts.items():\n",
    "    print(path_)\n",
    "    print(find_post_headers(post_text=''.join(text_)))\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EN post heahder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_header_copy = chn_posts.copy()\n",
    "en_header_dict = {}\n",
    "for path, text in en_header_copy.items():\n",
    "    en_path = path.replace('../','../en/')\n",
    "    en_header_dict[en_path] = find_post_headers(post_text=''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key_ = list(en_header_dict.keys())[25]\n",
    "print(test_key_)\n",
    "print(en_header_dict[test_key_])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EN post content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_posts_new = {}\n",
    "for path, text in en_posts_copy.items():\n",
    "    en_path = path.replace('../','../en/')\n",
    "    en_posts_new[en_path] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key = list(en_posts_copy.keys())[2]\n",
    "print(en_posts_copy[test_key])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the EN files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for en_path_, header_ in en_header_dict.items():\n",
    "    filename = Path(en_path_).parent\n",
    "    filename.mkdir(parents=True, exist_ok=True)\n",
    "    filename.touch(exist_ok=True)\n",
    "    try:\n",
    "        with open(en_path_, 'r') as f:\n",
    "            original_text_ = f.readlines()\n",
    "            new_post_ = header_ + ''.join(original_text_)\n",
    "\n",
    "            with open(en_path_, 'w') as new_file:\n",
    "                new_file.write(new_post_)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for en_path_, text_ in en_posts_new.items():\n",
    "    filename = Path(en_path_).parent\n",
    "    filename.mkdir(parents=True, exist_ok=True)\n",
    "    filename.touch(exist_ok=True)\n",
    "    with open(en_path_, 'w+') as f:\n",
    "\n",
    "        f.writelines(text_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
